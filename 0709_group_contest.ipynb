{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T01:21:55.484593Z",
     "start_time": "2018-07-10T01:21:55.463959Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T10:22:33.404691Z",
     "start_time": "2018-07-09T10:22:33.321341Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"database.pkl\")\n",
    "data = df[\"Close\"].values\n",
    "signal = np.load(\"trading_signal.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T09:48:00.850461Z",
     "start_time": "2018-07-09T09:48:00.844284Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [-1]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T09:48:05.453610Z",
     "start_time": "2018-07-09T09:48:05.443196Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode\n",
    "y_train = to_categorical(signal, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T09:48:17.249280Z",
     "start_time": "2018-07-09T09:48:17.237010Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitibanc/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Standardize\n",
    "standardize = preprocessing.scale(data)\n",
    "# Scaling\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "x_scaled = scaler.fit_transform(standardize.reshape(standardize.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestep Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T09:49:26.323942Z",
     "start_time": "2018-07-09T09:49:25.606561Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_step = 30\n",
    "d = np.zeros((x_scaled.shape[0] - time_step + 1, 30, 1))\n",
    "y_step = np.zeros((y_train.shape[0] - time_step + 1, time_step, 13))\n",
    "for i in range(d.shape[0]):\n",
    "    d[i] = x_scaled[i:i + time_step]\n",
    "    if i < y_step.shape[0]:\n",
    "        y_step[i] = y_train[i:i + time_step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T09:49:32.480463Z",
     "start_time": "2018-07-09T09:49:32.475380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "x_train = d[:signal.shape[0]]\n",
    "x_test = d[signal.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T11:56:26.014867Z",
     "start_time": "2018-07-09T11:56:26.011765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Return Values\n",
    "return_x = df[\"Close\"].values - df[\"Open\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T11:56:28.415291Z",
     "start_time": "2018-07-09T11:56:28.408129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize\n",
    "# return_x = preprocessing.scale(return_x)\n",
    "return_x = return_x.astype(\"float32\") - np.mean(return_x)\n",
    "# Scaling\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "return_x = scaler.fit_transform(standardize.reshape(return_x.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T11:56:40.023599Z",
     "start_time": "2018-07-09T11:56:39.761392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Timestep Splitting\n",
    "tmp = np.zeros((return_x.shape[0] - time_step + 1, 30, 1))\n",
    "for i in range(d.shape[0]):\n",
    "    tmp[i] = return_x[i:i + time_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T11:56:41.361495Z",
     "start_time": "2018-07-09T11:56:41.356937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train/Test Splitting\n",
    "return_x_train = tmp[:signal.shape[0]]\n",
    "return_x_test = tmp[signal.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:04:41.536726Z",
     "start_time": "2018-07-09T12:04:41.490263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 13)                221       \n",
      "=================================================================\n",
      "Total params: 11,341\n",
      "Trainable params: 11,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0 = Sequential()\n",
    "# model0.add(Flatten(input_shape=(30,1), name=\"input\"))\n",
    "model0.add(Dense(128, activation=\"tanh\", input_shape=(1,), name=\"fc1\"))\n",
    "model0.add(Dense(64, activation=\"tanh\", name=\"fc2\"))\n",
    "model0.add(Dense(32, activation=\"tanh\", name=\"fc3\"))\n",
    "model0.add(Dense(16, activation=\"tanh\", name=\"fc4\"))\n",
    "model0.add(Dense(13, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:04:45.980388Z",
     "start_time": "2018-07-09T12:04:45.952020Z"
    }
   },
   "outputs": [],
   "source": [
    "model0.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T12:06:06.150764Z",
     "start_time": "2018-07-09T12:04:47.285116Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 243000 samples, validate on 27000 samples\n",
      "Epoch 1/500\n",
      "243000/243000 [==============================] - 3s 13us/step - loss: 0.9893 - acc: 0.7046 - mean_squared_error: 0.0364 - val_loss: 0.9534 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 2/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9719 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9528 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 3/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9522 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 4/500\n",
      "243000/243000 [==============================] - 3s 10us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9528 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 5/500\n",
      "243000/243000 [==============================] - 3s 10us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9521 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 6/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9530 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 7/500\n",
      "243000/243000 [==============================] - 3s 12us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9523 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 8/500\n",
      "243000/243000 [==============================] - 3s 12us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9527 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 9/500\n",
      "243000/243000 [==============================] - 3s 13us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9520 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 10/500\n",
      "243000/243000 [==============================] - 3s 12us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9525 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 11/500\n",
      "243000/243000 [==============================] - 3s 12us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9524 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 12/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9536 - val_acc: 0.7147 - val_mean_squared_error: 0.0355\n",
      "Epoch 13/500\n",
      "243000/243000 [==============================] - 3s 12us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9519 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 14/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9519 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 15/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9523 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 16/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9718 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9529 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 17/500\n",
      "243000/243000 [==============================] - 3s 13us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9521 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 18/500\n",
      "243000/243000 [==============================] - 4s 15us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9517 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 19/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9519 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 20/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9530 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 21/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9523 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 22/500\n",
      "243000/243000 [==============================] - 3s 13us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9519 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 23/500\n",
      "243000/243000 [==============================] - 3s 12us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9522 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 24/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9531 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 25/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9522 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 26/500\n",
      "243000/243000 [==============================] - 3s 11us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9524 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 27/500\n",
      "243000/243000 [==============================] - 3s 10us/step - loss: 0.9716 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9527 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n",
      "Epoch 28/500\n",
      "243000/243000 [==============================] - 3s 12us/step - loss: 0.9717 - acc: 0.7064 - mean_squared_error: 0.0362 - val_loss: 0.9522 - val_acc: 0.7147 - val_mean_squared_error: 0.0354\n"
     ]
    }
   ],
   "source": [
    "history0 = model0.fit(data[:270000], y_train, batch_size=128, epochs=500, validation_split=0.1, callbacks=[EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T13:54:40.800154Z",
     "start_time": "2018-07-09T13:54:40.793598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 16\n",
    "batch_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T10:41:23.741010Z",
     "start_time": "2018-07-09T10:41:23.589622Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm1 (LSTM)                 (300, 30, 16)             1152      \n",
      "_________________________________________________________________\n",
      "flatten1 (Flatten)           (300, 480)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (300, 64)                 30784     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (300, 32)                 2080      \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (300, 16)                 528       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (300, 13)                 221       \n",
      "=================================================================\n",
      "Total params: 34,765\n",
      "Trainable params: 34,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(LSTM(latent_dim, return_sequences=True, batch_input_shape=(batch_size, time_step, 1), name=\"lstm1\"))\n",
    "model1.add(Flatten(name=\"flatten1\"))\n",
    "model1.add(Dense(64, activation=\"tanh\", name=\"fc1\"))\n",
    "model1.add(Dense(32, activation=\"tanh\", name=\"fc2\"))\n",
    "model1.add(Dense(16, activation=\"tanh\", name=\"fc3\"))\n",
    "model1.add(Dense(13, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:00:49.904420Z",
     "start_time": "2018-07-09T14:00:49.876138Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T10:46:02.419801Z",
     "start_time": "2018-07-09T10:41:32.384424Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 243000 samples, validate on 27000 samples\n",
      "Epoch 1/300\n",
      "243000/243000 [==============================] - 9s 36us/step - loss: 1.0329 - acc: 0.7017 - val_loss: 0.9532 - val_acc: 0.7147\n",
      "Epoch 2/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9719 - acc: 0.7064 - val_loss: 0.9524 - val_acc: 0.7147\n",
      "Epoch 3/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9715 - acc: 0.7064 - val_loss: 0.9522 - val_acc: 0.7147\n",
      "Epoch 4/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9522 - val_acc: 0.7147\n",
      "Epoch 5/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 6/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 7/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 8/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 9/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 10/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 11/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 12/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 13/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 14/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 15/300\n",
      "243000/243000 [==============================] - 8s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 16/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 17/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 18/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 19/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 20/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 21/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 22/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 23/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 24/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 25/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 26/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 27/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 28/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 29/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 30/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 31/300\n",
      "243000/243000 [==============================] - 9s 35us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n",
      "Epoch 32/300\n",
      "243000/243000 [==============================] - 8s 34us/step - loss: 0.9714 - acc: 0.7064 - val_loss: 0.9521 - val_acc: 0.7147\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(return_x_train, y_train, batch_size=300, epochs=300, validation_split=0.1, shuffle=False, callbacks=[EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-09T14:04:32.922Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = {}\n",
    "h[\"loss\"] = []\n",
    "h[\"acc\"] = []\n",
    "h[\"val_loss\"] = []\n",
    "h[\"val_acc\"] = []\n",
    "for e in range(100):\n",
    "    for b in range(return_x_train.shape[0]-1000 // batch_size):\n",
    "        # Random select batch data\n",
    "        idx = np.random.randint(0, return_x_train.shape[0]-1000, batch_size)\n",
    "        loss, acc = model1.train_on_batch(return_x_train[idx], y_train[idx])\n",
    "    loss, acc = model1.evaluate(return_x_train, y_train, batch_size=batch_size)\n",
    "    val_loss, val_acc = model1.evaluate(return_x_train[return_x_train.shape[0]-1000:], y_train[return_x_train.shape[0]-1000:], batch_size=batch_size)\n",
    "    print(\"Epoch %d/100\\tloss: %.4f - acc: %.4f - val_loss: %.4f - val_acc: %.4f\" % (e+1, loss, acc, val_loss, val_acc))\n",
    "    h[\"loss\"].append(loss)\n",
    "    h[\"acc\"].append(acc)\n",
    "    h[\"val_loss\"].append(val_loss)\n",
    "    h[\"val_acc\"].append(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T10:06:33.300854Z",
     "start_time": "2018-07-09T10:06:33.152143Z"
    }
   },
   "outputs": [],
   "source": [
    "preds1 = model1.predict(x_test[:3000], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T10:15:55.296514Z",
     "start_time": "2018-07-09T10:15:55.289958Z"
    }
   },
   "outputs": [],
   "source": [
    "preds1 = np.argmax(preds1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 偉嘉Ver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T01:19:40.913166Z",
     "start_time": "2018-07-10T01:19:39.888616Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jul  9 14:31:02 2018\n",
    "\n",
    "@author: chia\n",
    "\"\"\"\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#train_data, test_data = data[:270000], data[270000:]\n",
    "\n",
    "target = np.array(pd.get_dummies(signal.flatten()))\n",
    "y_target = signal+6\n",
    "y_target = y_target[30:]\n",
    "\n",
    "Kseconds = 30\n",
    "epochs = 300\n",
    "batch = 2048\n",
    "\n",
    "\n",
    "def normalization_for_class(x):\n",
    "    sc = MinMaxScaler()\n",
    "    ss = StandardScaler()\n",
    "#    x = sc.fit_transform(x.reshape(x.shape[0],1))\n",
    "    x = ss.fit_transform(x.reshape(x.shape[0], 1))\n",
    "    return x, ss\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "\n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "\n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "\n",
    "    weights = K.variable(weights)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cal_return_old(data):  # 用來算Return\n",
    "    after_price = np.array(data)\n",
    "    current_price = np.insert(after_price, 0, 0)  # 前補0\n",
    "    after_price = np.append(after_price, 0)  # 後補0\n",
    "\n",
    "    # 後一秒(after_price) - 前一秒(current_price)\n",
    "    secReturn = (after_price - current_price)\n",
    "\n",
    "    secReturn = np.delete(secReturn, [0, len(secReturn)-1])  # 去除最頭最尾\n",
    "    return secReturn\n",
    "\n",
    "\n",
    "return_ = cal_return_old(data)\n",
    "\n",
    "#data, ss = normalization_for_class(data)\n",
    "#data = data.flatten()\n",
    "\n",
    "return_, ss = normalization_for_class(return_)\n",
    "return_ = return_.flatten()\n",
    "\n",
    "\"\"\"#price\"\"\"\n",
    "x_train_price = np.zeros((data.shape[0] - Kseconds + 1, Kseconds))\n",
    "\n",
    "for i in range(x_train_price.shape[0]):\n",
    "    x_train_price[i] = data[i: i + Kseconds]\n",
    "\n",
    "x_train_price, x_test_price = x_train_price[:270000], x_train_price[270000:]\n",
    "\n",
    "a = np.mean(x_train_price, axis=1)\n",
    "a = np.repeat(a, Kseconds, axis=0)\n",
    "a = a.reshape(int(a.shape[0]/Kseconds), Kseconds)\n",
    "data_sampling = x_train_price - a\n",
    "b = np.mean(x_test_price, axis=1)\n",
    "b = np.repeat(b, Kseconds, axis=0)\n",
    "b = b.reshape(int(b.shape[0]/Kseconds), Kseconds)\n",
    "data_sampling_test = x_test_price - b\n",
    "\n",
    "\"\"\"#return\"\"\"\n",
    "x_train = np.zeros((return_.shape[0] - Kseconds + 1, Kseconds))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train[i] = return_[i: i + Kseconds]\n",
    "\n",
    "x_train, x_test = x_train[:270000-Kseconds], x_train[270000-Kseconds:]\n",
    "y_train = target\n",
    "\n",
    "nb_class = 13\n",
    "\n",
    "unique, counts = np.unique(signal, return_counts=True)\n",
    "sum_dict = dict(zip(unique+6, counts))\n",
    "c = np.zeros(13)\n",
    "for i in range(13):\n",
    "    c[i] = 270000 / (sum_dict[i] * nb_class)\n",
    "weights = dict(zip(unique+6, c))\n",
    "\n",
    "#from sklearn.utils import class_weight\n",
    "#sample_weights = class_weight.compute_sample_weight('balanced', signal[29:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T02:19:45.418652Z",
     "start_time": "2018-07-10T02:19:45.274172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 25, 36)            252       \n",
      "_________________________________________________________________\n",
      "prelu_1 (PReLU)              (None, 25, 36)            900       \n",
      "_________________________________________________________________\n",
      "faltten (Flatten)            (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 64)                57664     \n",
      "_________________________________________________________________\n",
      "prelu_2 (PReLU)              (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "prelu_3 (PReLU)              (None, 32)                32        \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "prelu_4 (PReLU)              (None, 16)                16        \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 13)                221       \n",
      "=================================================================\n",
      "Total params: 61,757\n",
      "Trainable params: 61,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn(window_size, nb_input_series, output_dim=1):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=36, kernel_size=6,\n",
    "                     input_shape=(window_size, nb_input_series), name=\"conv1d\"))\n",
    "    model.add(PReLU(name=\"prelu_1\"))\n",
    "    model.add(Flatten(name=\"faltten\"))\n",
    "    model.add(Dense(64, kernel_regularizer=\"l2\", name=\"fc1\"))\n",
    "    model.add(PReLU(name=\"prelu_2\"))\n",
    "    model.add(Dense(32, kernel_regularizer=\"l2\", name=\"fc2\"))\n",
    "    model.add(PReLU(name=\"prelu_3\"))\n",
    "    model.add(Dense(16, kernel_regularizer=\"l2\", name=\"fc3\"))\n",
    "    model.add(PReLU(name=\"prelu_4\"))\n",
    "    model.add(Dense(output_dim, activation=\"softmax\", name=\"output\"))\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def cnn_train(model, x, y, epochs=100):\n",
    "    x = np.reshape(x, (x.shape[0], x.shape[1], 1))\n",
    "    train_fit = model.fit(x=x, y=y, validation_split=0.1,\n",
    "                          epochs=epochs, batch_size=batch, callbacks=[EarlyStopping(patience=20)])\n",
    "    return model, train_fit\n",
    "\n",
    "\n",
    "#自己的解 (正確的，能overfitting，目前用price減去每條time-series平均處理)\n",
    "#model, history = cnn_train(cnn(data_sampling[29:].shape[1], 1, output_dim = 13, loss = \"categorical_crossentropy\"), data_sampling[29:], y_train[29:], epochs = 100)\n",
    "\n",
    "#print(\"Predicting cnn...\")\n",
    "#predict_test = model.predict(data_sampling_test.reshape(data_sampling_test.shape[0],data_sampling_test.shape[1],1))\n",
    "#predict_train = model.predict(data_sampling.reshape(data_sampling.shape[0],x_train.shape[1],1))\n",
    "#    \n",
    "#loss_test = model.evaluate(data_sampling_test.reshape(data_sampling_test.shape[0],data_sampling_test.shape[1],1), predict_test)\n",
    "#\n",
    "#test = np.argmax(predict_test, axis = 1) - 6\n",
    "#train = np.argmax(predict_train, axis = 1) - 6\n",
    "\n",
    "# 頭哥解\n",
    "model = cnn(x_train.shape[1], 1, output_dim=13)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T02:20:25.034959Z",
     "start_time": "2018-07-10T02:19:50.734013Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11700 samples, validate on 1300 samples\n",
      "Epoch 1/500\n",
      "11700/11700 [==============================] - 1s 124us/step - loss: 3.6029 - acc: 0.2069 - mean_absolute_error: 5.9349 - val_loss: 3.0110 - val_acc: 0.2915 - val_mean_absolute_error: 5.9349\n",
      "Epoch 2/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 2.6711 - acc: 0.3131 - mean_absolute_error: 5.9349 - val_loss: 2.3735 - val_acc: 0.3792 - val_mean_absolute_error: 5.9349\n",
      "Epoch 3/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 2.2292 - acc: 0.4071 - mean_absolute_error: 5.9349 - val_loss: 2.1247 - val_acc: 0.4500 - val_mean_absolute_error: 5.9349\n",
      "Epoch 4/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 2.0169 - acc: 0.4585 - mean_absolute_error: 5.9349 - val_loss: 1.9856 - val_acc: 0.4738 - val_mean_absolute_error: 5.9349\n",
      "Epoch 5/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.8897 - acc: 0.4897 - mean_absolute_error: 5.9349 - val_loss: 1.8661 - val_acc: 0.5069 - val_mean_absolute_error: 5.9349\n",
      "Epoch 6/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.7927 - acc: 0.5201 - mean_absolute_error: 5.9349 - val_loss: 1.7887 - val_acc: 0.4985 - val_mean_absolute_error: 5.9349\n",
      "Epoch 7/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.7230 - acc: 0.5381 - mean_absolute_error: 5.9349 - val_loss: 1.7328 - val_acc: 0.5338 - val_mean_absolute_error: 5.9349\n",
      "Epoch 8/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.6590 - acc: 0.5575 - mean_absolute_error: 5.9349 - val_loss: 1.6328 - val_acc: 0.5831 - val_mean_absolute_error: 5.9349\n",
      "Epoch 9/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.5976 - acc: 0.5736 - mean_absolute_error: 5.9349 - val_loss: 1.5981 - val_acc: 0.5962 - val_mean_absolute_error: 5.9349\n",
      "Epoch 10/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.5346 - acc: 0.5948 - mean_absolute_error: 5.9349 - val_loss: 1.5491 - val_acc: 0.5885 - val_mean_absolute_error: 5.9349\n",
      "Epoch 11/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.4927 - acc: 0.6091 - mean_absolute_error: 5.9349 - val_loss: 1.5094 - val_acc: 0.6062 - val_mean_absolute_error: 5.9349\n",
      "Epoch 12/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.4438 - acc: 0.6233 - mean_absolute_error: 5.9349 - val_loss: 1.4494 - val_acc: 0.6315 - val_mean_absolute_error: 5.9349\n",
      "Epoch 13/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.4089 - acc: 0.6396 - mean_absolute_error: 5.9349 - val_loss: 1.4529 - val_acc: 0.6162 - val_mean_absolute_error: 5.9349\n",
      "Epoch 14/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.3799 - acc: 0.6472 - mean_absolute_error: 5.9349 - val_loss: 1.3984 - val_acc: 0.6408 - val_mean_absolute_error: 5.9349\n",
      "Epoch 15/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.3479 - acc: 0.6575 - mean_absolute_error: 5.9349 - val_loss: 1.3649 - val_acc: 0.6592 - val_mean_absolute_error: 5.9349\n",
      "Epoch 16/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.3243 - acc: 0.6678 - mean_absolute_error: 5.9349 - val_loss: 1.3552 - val_acc: 0.6562 - val_mean_absolute_error: 5.9349\n",
      "Epoch 17/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.2930 - acc: 0.6726 - mean_absolute_error: 5.9349 - val_loss: 1.3506 - val_acc: 0.6546 - val_mean_absolute_error: 5.9349\n",
      "Epoch 18/500\n",
      "11700/11700 [==============================] - 0s 24us/step - loss: 1.2696 - acc: 0.6839 - mean_absolute_error: 5.9349 - val_loss: 1.3164 - val_acc: 0.6754 - val_mean_absolute_error: 5.9349\n",
      "Epoch 19/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.2413 - acc: 0.6948 - mean_absolute_error: 5.9349 - val_loss: 1.2865 - val_acc: 0.6808 - val_mean_absolute_error: 5.9349\n",
      "Epoch 20/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.2242 - acc: 0.7003 - mean_absolute_error: 5.9349 - val_loss: 1.2873 - val_acc: 0.6731 - val_mean_absolute_error: 5.9349\n",
      "Epoch 21/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.2085 - acc: 0.7062 - mean_absolute_error: 5.9349 - val_loss: 1.2770 - val_acc: 0.6854 - val_mean_absolute_error: 5.9349\n",
      "Epoch 22/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.1909 - acc: 0.7079 - mean_absolute_error: 5.9349 - val_loss: 1.2475 - val_acc: 0.6854 - val_mean_absolute_error: 5.9349\n",
      "Epoch 23/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.1710 - acc: 0.7159 - mean_absolute_error: 5.9349 - val_loss: 1.2822 - val_acc: 0.6754 - val_mean_absolute_error: 5.9349\n",
      "Epoch 24/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.1546 - acc: 0.7208 - mean_absolute_error: 5.9349 - val_loss: 1.2191 - val_acc: 0.6954 - val_mean_absolute_error: 5.9349\n",
      "Epoch 25/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.1319 - acc: 0.7265 - mean_absolute_error: 5.9349 - val_loss: 1.2099 - val_acc: 0.6938 - val_mean_absolute_error: 5.9349\n",
      "Epoch 26/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.1264 - acc: 0.7303 - mean_absolute_error: 5.9349 - val_loss: 1.1882 - val_acc: 0.7031 - val_mean_absolute_error: 5.9349\n",
      "Epoch 27/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.1042 - acc: 0.7343 - mean_absolute_error: 5.9349 - val_loss: 1.2111 - val_acc: 0.6962 - val_mean_absolute_error: 5.9349\n",
      "Epoch 28/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.1019 - acc: 0.7359 - mean_absolute_error: 5.9349 - val_loss: 1.1847 - val_acc: 0.7085 - val_mean_absolute_error: 5.9349\n",
      "Epoch 29/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.0816 - acc: 0.7405 - mean_absolute_error: 5.9349 - val_loss: 1.1764 - val_acc: 0.6954 - val_mean_absolute_error: 5.9349\n",
      "Epoch 30/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.0739 - acc: 0.7428 - mean_absolute_error: 5.9349 - val_loss: 1.1774 - val_acc: 0.7200 - val_mean_absolute_error: 5.9349\n",
      "Epoch 31/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.0515 - acc: 0.7520 - mean_absolute_error: 5.9349 - val_loss: 1.1456 - val_acc: 0.7192 - val_mean_absolute_error: 5.9349\n",
      "Epoch 32/500\n",
      "11700/11700 [==============================] - 0s 26us/step - loss: 1.0493 - acc: 0.7463 - mean_absolute_error: 5.9349 - val_loss: 1.1646 - val_acc: 0.7031 - val_mean_absolute_error: 5.9349\n",
      "Epoch 33/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.0330 - acc: 0.7551 - mean_absolute_error: 5.9349 - val_loss: 1.1802 - val_acc: 0.7015 - val_mean_absolute_error: 5.9349\n",
      "Epoch 34/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.0439 - acc: 0.7526 - mean_absolute_error: 5.9349 - val_loss: 1.1582 - val_acc: 0.7008 - val_mean_absolute_error: 5.9349\n",
      "Epoch 35/500\n",
      "11700/11700 [==============================] - 0s 26us/step - loss: 1.0331 - acc: 0.7560 - mean_absolute_error: 5.9349 - val_loss: 1.1252 - val_acc: 0.7285 - val_mean_absolute_error: 5.9349\n",
      "Epoch 36/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 1.0085 - acc: 0.7624 - mean_absolute_error: 5.9349 - val_loss: 1.1496 - val_acc: 0.7100 - val_mean_absolute_error: 5.9349\n",
      "Epoch 37/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9997 - acc: 0.7642 - mean_absolute_error: 5.9349 - val_loss: 1.1280 - val_acc: 0.7015 - val_mean_absolute_error: 5.9349\n",
      "Epoch 38/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9833 - acc: 0.7702 - mean_absolute_error: 5.9349 - val_loss: 1.0959 - val_acc: 0.7208 - val_mean_absolute_error: 5.9349\n",
      "Epoch 39/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9732 - acc: 0.7704 - mean_absolute_error: 5.9349 - val_loss: 1.1270 - val_acc: 0.7246 - val_mean_absolute_error: 5.9349\n",
      "Epoch 40/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9610 - acc: 0.7740 - mean_absolute_error: 5.9349 - val_loss: 1.0833 - val_acc: 0.7338 - val_mean_absolute_error: 5.9349\n",
      "Epoch 41/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9482 - acc: 0.7806 - mean_absolute_error: 5.9349 - val_loss: 1.1191 - val_acc: 0.7123 - val_mean_absolute_error: 5.9349\n",
      "Epoch 42/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9568 - acc: 0.7769 - mean_absolute_error: 5.9349 - val_loss: 1.0788 - val_acc: 0.7338 - val_mean_absolute_error: 5.9349\n",
      "Epoch 43/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9575 - acc: 0.7797 - mean_absolute_error: 5.9349 - val_loss: 1.0994 - val_acc: 0.7246 - val_mean_absolute_error: 5.9349\n",
      "Epoch 44/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9324 - acc: 0.7826 - mean_absolute_error: 5.9349 - val_loss: 1.0677 - val_acc: 0.7400 - val_mean_absolute_error: 5.9349\n",
      "Epoch 45/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9255 - acc: 0.7889 - mean_absolute_error: 5.9349 - val_loss: 1.0775 - val_acc: 0.7292 - val_mean_absolute_error: 5.9349\n",
      "Epoch 46/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9224 - acc: 0.7897 - mean_absolute_error: 5.9349 - val_loss: 1.0749 - val_acc: 0.7269 - val_mean_absolute_error: 5.9349\n",
      "Epoch 47/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9137 - acc: 0.7922 - mean_absolute_error: 5.9349 - val_loss: 1.1002 - val_acc: 0.7177 - val_mean_absolute_error: 5.9349\n",
      "Epoch 48/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9256 - acc: 0.7826 - mean_absolute_error: 5.9349 - val_loss: 1.0466 - val_acc: 0.7354 - val_mean_absolute_error: 5.9349\n",
      "Epoch 49/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9061 - acc: 0.7913 - mean_absolute_error: 5.9349 - val_loss: 1.0442 - val_acc: 0.7408 - val_mean_absolute_error: 5.9349\n",
      "Epoch 50/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9017 - acc: 0.7903 - mean_absolute_error: 5.9349 - val_loss: 1.0576 - val_acc: 0.7385 - val_mean_absolute_error: 5.9349\n",
      "Epoch 51/500\n",
      "11700/11700 [==============================] - 0s 26us/step - loss: 0.9007 - acc: 0.7932 - mean_absolute_error: 5.9349 - val_loss: 1.0234 - val_acc: 0.7446 - val_mean_absolute_error: 5.9349\n",
      "Epoch 52/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8935 - acc: 0.7963 - mean_absolute_error: 5.9349 - val_loss: 1.0879 - val_acc: 0.7123 - val_mean_absolute_error: 5.9349\n",
      "Epoch 53/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.9234 - acc: 0.7840 - mean_absolute_error: 5.9349 - val_loss: 1.0836 - val_acc: 0.7369 - val_mean_absolute_error: 5.9349\n",
      "Epoch 54/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8952 - acc: 0.7915 - mean_absolute_error: 5.9349 - val_loss: 1.0363 - val_acc: 0.7385 - val_mean_absolute_error: 5.9349\n",
      "Epoch 55/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8826 - acc: 0.7967 - mean_absolute_error: 5.9349 - val_loss: 1.0618 - val_acc: 0.7331 - val_mean_absolute_error: 5.9349\n",
      "Epoch 56/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8832 - acc: 0.7948 - mean_absolute_error: 5.9349 - val_loss: 1.0343 - val_acc: 0.7446 - val_mean_absolute_error: 5.9349\n",
      "Epoch 57/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8670 - acc: 0.8024 - mean_absolute_error: 5.9349 - val_loss: 1.0505 - val_acc: 0.7408 - val_mean_absolute_error: 5.9349\n",
      "Epoch 58/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8552 - acc: 0.8084 - mean_absolute_error: 5.9349 - val_loss: 1.0211 - val_acc: 0.7462 - val_mean_absolute_error: 5.9349\n",
      "Epoch 59/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8671 - acc: 0.8033 - mean_absolute_error: 5.9349 - val_loss: 1.0263 - val_acc: 0.7392 - val_mean_absolute_error: 5.9349\n",
      "Epoch 60/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8548 - acc: 0.7997 - mean_absolute_error: 5.9349 - val_loss: 1.0139 - val_acc: 0.7492 - val_mean_absolute_error: 5.9349\n",
      "Epoch 61/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8464 - acc: 0.8115 - mean_absolute_error: 5.9349 - val_loss: 1.0392 - val_acc: 0.7323 - val_mean_absolute_error: 5.9349\n",
      "Epoch 62/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8416 - acc: 0.8098 - mean_absolute_error: 5.9349 - val_loss: 1.0391 - val_acc: 0.7508 - val_mean_absolute_error: 5.9349\n",
      "Epoch 63/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8330 - acc: 0.8100 - mean_absolute_error: 5.9349 - val_loss: 1.0431 - val_acc: 0.7431 - val_mean_absolute_error: 5.9349\n",
      "Epoch 64/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8284 - acc: 0.8123 - mean_absolute_error: 5.9349 - val_loss: 1.0551 - val_acc: 0.7192 - val_mean_absolute_error: 5.9349\n",
      "Epoch 65/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8240 - acc: 0.8119 - mean_absolute_error: 5.9349 - val_loss: 1.0040 - val_acc: 0.7569 - val_mean_absolute_error: 5.9349\n",
      "Epoch 66/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8099 - acc: 0.8214 - mean_absolute_error: 5.9349 - val_loss: 1.0285 - val_acc: 0.7462 - val_mean_absolute_error: 5.9349\n",
      "Epoch 67/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8098 - acc: 0.8191 - mean_absolute_error: 5.9349 - val_loss: 1.0024 - val_acc: 0.7531 - val_mean_absolute_error: 5.9349\n",
      "Epoch 68/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8151 - acc: 0.8154 - mean_absolute_error: 5.9349 - val_loss: 1.0211 - val_acc: 0.7454 - val_mean_absolute_error: 5.9349\n",
      "Epoch 69/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8168 - acc: 0.8108 - mean_absolute_error: 5.9349 - val_loss: 1.0176 - val_acc: 0.7477 - val_mean_absolute_error: 5.9349\n",
      "Epoch 70/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8296 - acc: 0.8110 - mean_absolute_error: 5.9349 - val_loss: 1.0765 - val_acc: 0.7338 - val_mean_absolute_error: 5.9349\n",
      "Epoch 71/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8228 - acc: 0.8111 - mean_absolute_error: 5.9349 - val_loss: 1.0285 - val_acc: 0.7531 - val_mean_absolute_error: 5.9349\n",
      "Epoch 72/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8276 - acc: 0.8105 - mean_absolute_error: 5.9349 - val_loss: 1.0702 - val_acc: 0.7262 - val_mean_absolute_error: 5.9349\n",
      "Epoch 73/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8132 - acc: 0.8153 - mean_absolute_error: 5.9349 - val_loss: 1.0456 - val_acc: 0.7369 - val_mean_absolute_error: 5.9349\n",
      "Epoch 74/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8285 - acc: 0.8094 - mean_absolute_error: 5.9349 - val_loss: 1.0190 - val_acc: 0.7408 - val_mean_absolute_error: 5.9349\n",
      "Epoch 75/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8036 - acc: 0.8179 - mean_absolute_error: 5.9349 - val_loss: 1.0192 - val_acc: 0.7515 - val_mean_absolute_error: 5.9349\n",
      "Epoch 76/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.8029 - acc: 0.8207 - mean_absolute_error: 5.9349 - val_loss: 1.0217 - val_acc: 0.7423 - val_mean_absolute_error: 5.9349\n",
      "Epoch 77/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7833 - acc: 0.8262 - mean_absolute_error: 5.9349 - val_loss: 1.0183 - val_acc: 0.7592 - val_mean_absolute_error: 5.9349\n",
      "Epoch 78/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7741 - acc: 0.8305 - mean_absolute_error: 5.9349 - val_loss: 0.9897 - val_acc: 0.7631 - val_mean_absolute_error: 5.9349\n",
      "Epoch 79/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7808 - acc: 0.8262 - mean_absolute_error: 5.9349 - val_loss: 1.0158 - val_acc: 0.7523 - val_mean_absolute_error: 5.9349\n",
      "Epoch 80/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7529 - acc: 0.8376 - mean_absolute_error: 5.9349 - val_loss: 1.0066 - val_acc: 0.7577 - val_mean_absolute_error: 5.9349\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7482 - acc: 0.8359 - mean_absolute_error: 5.9349 - val_loss: 0.9879 - val_acc: 0.7469 - val_mean_absolute_error: 5.9349\n",
      "Epoch 82/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7681 - acc: 0.8271 - mean_absolute_error: 5.9349 - val_loss: 1.0289 - val_acc: 0.7423 - val_mean_absolute_error: 5.9349\n",
      "Epoch 83/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7670 - acc: 0.8300 - mean_absolute_error: 5.9349 - val_loss: 1.0270 - val_acc: 0.7469 - val_mean_absolute_error: 5.9349\n",
      "Epoch 84/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7587 - acc: 0.8299 - mean_absolute_error: 5.9349 - val_loss: 1.0118 - val_acc: 0.7515 - val_mean_absolute_error: 5.9349\n",
      "Epoch 85/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7433 - acc: 0.8399 - mean_absolute_error: 5.9349 - val_loss: 1.0128 - val_acc: 0.7569 - val_mean_absolute_error: 5.9349\n",
      "Epoch 86/500\n",
      "11700/11700 [==============================] - 0s 26us/step - loss: 0.7289 - acc: 0.8422 - mean_absolute_error: 5.9349 - val_loss: 1.0006 - val_acc: 0.7492 - val_mean_absolute_error: 5.9349\n",
      "Epoch 87/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7406 - acc: 0.8403 - mean_absolute_error: 5.9349 - val_loss: 1.0433 - val_acc: 0.7269 - val_mean_absolute_error: 5.9349\n",
      "Epoch 88/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7452 - acc: 0.8327 - mean_absolute_error: 5.9349 - val_loss: 1.0084 - val_acc: 0.7554 - val_mean_absolute_error: 5.9349\n",
      "Epoch 89/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7642 - acc: 0.8282 - mean_absolute_error: 5.9349 - val_loss: 1.0549 - val_acc: 0.7415 - val_mean_absolute_error: 5.9349\n",
      "Epoch 90/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7743 - acc: 0.8185 - mean_absolute_error: 5.9349 - val_loss: 1.0559 - val_acc: 0.7438 - val_mean_absolute_error: 5.9349\n",
      "Epoch 91/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7284 - acc: 0.8405 - mean_absolute_error: 5.9349 - val_loss: 0.9985 - val_acc: 0.7654 - val_mean_absolute_error: 5.9349\n",
      "Epoch 92/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7013 - acc: 0.8548 - mean_absolute_error: 5.9349 - val_loss: 0.9784 - val_acc: 0.7654 - val_mean_absolute_error: 5.9349\n",
      "Epoch 93/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7084 - acc: 0.8502 - mean_absolute_error: 5.9349 - val_loss: 1.0037 - val_acc: 0.7515 - val_mean_absolute_error: 5.9349\n",
      "Epoch 94/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7129 - acc: 0.8465 - mean_absolute_error: 5.9349 - val_loss: 1.0436 - val_acc: 0.7508 - val_mean_absolute_error: 5.9349\n",
      "Epoch 95/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7243 - acc: 0.8394 - mean_absolute_error: 5.9349 - val_loss: 1.0487 - val_acc: 0.7431 - val_mean_absolute_error: 5.9349\n",
      "Epoch 96/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7490 - acc: 0.8324 - mean_absolute_error: 5.9349 - val_loss: 1.0213 - val_acc: 0.7515 - val_mean_absolute_error: 5.9349\n",
      "Epoch 97/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7281 - acc: 0.8399 - mean_absolute_error: 5.9349 - val_loss: 1.0201 - val_acc: 0.7469 - val_mean_absolute_error: 5.9349\n",
      "Epoch 98/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7313 - acc: 0.8349 - mean_absolute_error: 5.9349 - val_loss: 1.0480 - val_acc: 0.7338 - val_mean_absolute_error: 5.9349\n",
      "Epoch 99/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7279 - acc: 0.8426 - mean_absolute_error: 5.9349 - val_loss: 1.0138 - val_acc: 0.7631 - val_mean_absolute_error: 5.9349\n",
      "Epoch 100/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7029 - acc: 0.8524 - mean_absolute_error: 5.9349 - val_loss: 1.0212 - val_acc: 0.7600 - val_mean_absolute_error: 5.9349\n",
      "Epoch 101/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.6936 - acc: 0.8566 - mean_absolute_error: 5.9349 - val_loss: 1.0410 - val_acc: 0.7454 - val_mean_absolute_error: 5.9349\n",
      "Epoch 102/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.6907 - acc: 0.8515 - mean_absolute_error: 5.9349 - val_loss: 1.0003 - val_acc: 0.7608 - val_mean_absolute_error: 5.9349\n",
      "Epoch 103/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7023 - acc: 0.8475 - mean_absolute_error: 5.9349 - val_loss: 1.0274 - val_acc: 0.7377 - val_mean_absolute_error: 5.9349\n",
      "Epoch 104/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7290 - acc: 0.8379 - mean_absolute_error: 5.9349 - val_loss: 1.0845 - val_acc: 0.7338 - val_mean_absolute_error: 5.9349\n",
      "Epoch 105/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7575 - acc: 0.8276 - mean_absolute_error: 5.9349 - val_loss: 1.0992 - val_acc: 0.7269 - val_mean_absolute_error: 5.9349\n",
      "Epoch 106/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7314 - acc: 0.8410 - mean_absolute_error: 5.9349 - val_loss: 1.0793 - val_acc: 0.7408 - val_mean_absolute_error: 5.9349\n",
      "Epoch 107/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7103 - acc: 0.8470 - mean_absolute_error: 5.9349 - val_loss: 1.0845 - val_acc: 0.7169 - val_mean_absolute_error: 5.9349\n",
      "Epoch 108/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.6973 - acc: 0.8514 - mean_absolute_error: 5.9349 - val_loss: 0.9939 - val_acc: 0.7615 - val_mean_absolute_error: 5.9349\n",
      "Epoch 109/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.6764 - acc: 0.8617 - mean_absolute_error: 5.9349 - val_loss: 1.0163 - val_acc: 0.7669 - val_mean_absolute_error: 5.9349\n",
      "Epoch 110/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.6777 - acc: 0.8626 - mean_absolute_error: 5.9349 - val_loss: 1.0411 - val_acc: 0.7523 - val_mean_absolute_error: 5.9349\n",
      "Epoch 111/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7743 - acc: 0.8216 - mean_absolute_error: 5.9349 - val_loss: 1.0531 - val_acc: 0.7500 - val_mean_absolute_error: 5.9349\n",
      "Epoch 112/500\n",
      "11700/11700 [==============================] - 0s 25us/step - loss: 0.7118 - acc: 0.8491 - mean_absolute_error: 5.9349 - val_loss: 1.0584 - val_acc: 0.7400 - val_mean_absolute_error: 5.9349\n"
     ]
    }
   ],
   "source": [
    "iidx = np.arange(270000-Kseconds).reshape(270000-Kseconds, 1)\n",
    "w = np.array([100]*13)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "for ii in range(1):\n",
    "    mat_idx = np.array([])\n",
    "    for t in range(10):\n",
    "        for c in range(13):\n",
    "            leng = y_target[y_target == c].shape[0]\n",
    "            temp = iidx[y_target == c]\n",
    "            idx = np.random.randint(0, high=leng, size=w[c])\n",
    "            mat_idx = np.append(mat_idx, temp[idx]).astype('int32')\n",
    "    history = model.fit(x_train[mat_idx], y_target[mat_idx, :],\n",
    "                        epochs=500, batch_size=256, validation_split=0.1, callbacks=[EarlyStopping(patience=20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T02:11:02.654121Z",
     "start_time": "2018-07-10T02:10:50.630313Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test = model.predict(x_test.reshape(\n",
    "    x_test.shape[0], x_test.shape[1], 1))\n",
    "predict_train = model.predict(x_train.reshape(\n",
    "    x_train.shape[0], x_train.shape[1], 1))\n",
    "# Predict probability to categorical\n",
    "pred_test = np.argmax(predict_test, axis=1) - 6\n",
    "pred_train = np.argmax(predict_train, axis=1) - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T02:12:50.591070Z",
     "start_time": "2018-07-10T02:12:50.582323Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"pred7231\", pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "752px",
    "left": "27px",
    "top": "133px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "210px",
    "left": "1391px",
    "right": "18px",
    "top": "2px",
    "width": "511px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
