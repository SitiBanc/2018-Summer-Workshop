{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq Chat-bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:21.880051Z",
     "start_time": "2018-07-17T08:49:21.873330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nquestions = []\\nanswers = []\\nis_q = True\\ncounter = 0\\nwith open(\"clr_conversation.txt\", mode=\"r\") as f:\\n    for line in f:\\n        if is_q:\\n            questions.extend(line.strip().split())\\n            is_q = False\\n        else:\\n            answers.extend(line.strip().split())\\n            is_q = True\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read training data\n",
    "'''\n",
    "questions = []\n",
    "answers = []\n",
    "is_q = True\n",
    "counter = 0\n",
    "with open(\"clr_conversation.txt\", mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        if is_q:\n",
    "            questions.extend(line.strip().split())\n",
    "            is_q = False\n",
    "        else:\n",
    "            answers.extend(line.strip().split())\n",
    "            is_q = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq Transaltion\n",
    "\n",
    "ref\n",
    "- [keras blog](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
    "    - [github](https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:34.006921Z",
     "start_time": "2018-07-17T08:49:21.881113Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitibanc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:34.023508Z",
     "start_time": "2018-07-17T08:49:34.011753Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = \"fra.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:34.349689Z",
     "start_time": "2018-07-17T08:49:34.029045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\") # txt format: ENG\\tFR\\n\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split(\"\\t\")    # Split x/y\n",
    "    # We use \"\\t\" as \"BOS\" token\n",
    "    # for the targets, and \"\\n\" as \"EOS\" token\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"    # Add tokens\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:34.359737Z",
     "start_time": "2018-07-17T08:49:34.351093Z"
    }
   },
   "outputs": [],
   "source": [
    "# set to list and sort\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "# count input and target languages tokens (may be different)\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# count max sequence length of input and target language data respectively (may be different)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:34.454767Z",
     "start_time": "2018-07-17T08:49:34.360747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 94\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:34.534864Z",
     "start_time": "2018-07-17T08:49:34.460907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build (char2index) dictionary\n",
    "input_char2index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_char2index = dict(\n",
    "[(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:34.808441Z",
     "start_time": "2018-07-17T08:49:34.539124Z"
    }
   },
   "outputs": [],
   "source": [
    "# One-hot Encoding\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):    # zip to create (input, target) tuples\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_char2index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_char2index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_char2index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T08:49:35.823862Z",
     "start_time": "2018-07-17T08:49:34.809446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, None, 94)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 256), (None, 335872      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  359424      decoder_input[0][0]              \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, None, 94)     24158       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 719,454\n",
      "Trainable params: 719,454\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name=\"encoder_input\")    # 16*71\n",
    "encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True, name=\"encoder_lstm\")(encoder_inputs)    # 16*256, 16*256, 16*256\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name=\"decoder_input\")    # 59*94\n",
    "decoder_outputs, _, _ = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"decoder_lstm\")(decoder_inputs, initial_state=encoder_states)    # 59*256\n",
    "decoder_outputs = Dense(num_decoder_tokens, activation=\"softmax\", name=\"decoder_output\")(decoder_outputs)    # 59*94\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"seq2seq\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:27:28.882651Z",
     "start_time": "2018-07-17T08:49:35.824803Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 24s 3ms/step - loss: 1.1334 - val_loss: 1.1457\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9364 - val_loss: 1.1066\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.8983 - val_loss: 1.0524\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.8459 - val_loss: 0.9794\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.7816 - val_loss: 0.9065\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.7281 - val_loss: 0.8665\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.6864 - val_loss: 0.8258\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.6523 - val_loss: 0.7917\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.6261 - val_loss: 0.7663\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.6052 - val_loss: 0.7435\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5891 - val_loss: 0.7306\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5722 - val_loss: 0.7131\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5588 - val_loss: 0.7076\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5485 - val_loss: 0.6845\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5373 - val_loss: 0.6787\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5284 - val_loss: 0.6681\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5196 - val_loss: 0.6611\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5127 - val_loss: 0.6552\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.5075 - val_loss: 0.6476\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4971 - val_loss: 0.6405\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4903 - val_loss: 0.6348\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4830 - val_loss: 0.6263\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4765 - val_loss: 0.6187\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4700 - val_loss: 0.6194\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4642 - val_loss: 0.6120\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4574 - val_loss: 0.6042\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4520 - val_loss: 0.5992\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4459 - val_loss: 0.5950\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4414 - val_loss: 0.5901\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4362 - val_loss: 0.5858\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4295 - val_loss: 0.5823\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4250 - val_loss: 0.5772\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4209 - val_loss: 0.5734\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4149 - val_loss: 0.5657\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4107 - val_loss: 0.5655\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4062 - val_loss: 0.5598\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.4017 - val_loss: 0.5589\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3981 - val_loss: 0.5562\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3933 - val_loss: 0.5528\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3896 - val_loss: 0.5483\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3856 - val_loss: 0.5451\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3808 - val_loss: 0.5417\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3770 - val_loss: 0.5413\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3733 - val_loss: 0.5388\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3691 - val_loss: 0.5391\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3653 - val_loss: 0.5347\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3612 - val_loss: 0.5296\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3577 - val_loss: 0.5279\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3540 - val_loss: 0.5256\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3517 - val_loss: 0.5254\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3477 - val_loss: 0.5237\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3436 - val_loss: 0.5211\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3404 - val_loss: 0.5206\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3384 - val_loss: 0.5182\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3354 - val_loss: 0.5172\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3312 - val_loss: 0.5170\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3281 - val_loss: 0.5113\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3247 - val_loss: 0.5174\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3219 - val_loss: 0.5146\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3189 - val_loss: 0.5076\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3159 - val_loss: 0.5101\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3127 - val_loss: 0.5106\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3104 - val_loss: 0.5058\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3069 - val_loss: 0.5084\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3044 - val_loss: 0.5040\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.3010 - val_loss: 0.5078\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2985 - val_loss: 0.5056\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2957 - val_loss: 0.5045\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2932 - val_loss: 0.5054\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2906 - val_loss: 0.5038\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2868 - val_loss: 0.5032\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2851 - val_loss: 0.5029\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2821 - val_loss: 0.5048\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2794 - val_loss: 0.5038\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2764 - val_loss: 0.5026\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2741 - val_loss: 0.5033\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2722 - val_loss: 0.5012\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2692 - val_loss: 0.5051\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2668 - val_loss: 0.5052\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2648 - val_loss: 0.5020\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2608 - val_loss: 0.5059\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2591 - val_loss: 0.5034\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2565 - val_loss: 0.5094\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2552 - val_loss: 0.5052\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2520 - val_loss: 0.5087\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2489 - val_loss: 0.5077\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2466 - val_loss: 0.5105\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2452 - val_loss: 0.5074\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2435 - val_loss: 0.5058\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2397 - val_loss: 0.5122\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2378 - val_loss: 0.5106\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2345 - val_loss: 0.5100\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2329 - val_loss: 0.5094\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2307 - val_loss: 0.5139\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2285 - val_loss: 0.5178\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2265 - val_loss: 0.5201\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2248 - val_loss: 0.5145\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2220 - val_loss: 0.5261\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2199 - val_loss: 0.5190\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 0.2168 - val_loss: 0.5204\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:27:29.210953Z",
     "start_time": "2018-07-17T09:27:28.883653Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitibanc/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2368: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'encoder_lstm/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(\"seq2seq-translate.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:27:29.293028Z",
     "start_time": "2018-07-17T09:27:29.212065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"test\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:27:29.492846Z",
     "start_time": "2018-07-17T09:27:29.293981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Encoder & Decoder Model\n",
    "encoder_model = Model(encoder_inputs, encoder_states, name=\"Encoder\")\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name=\"hidden_state_input\")\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name=\"memory_cell_input\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    # decoder initial states\n",
    "decoder_outputs, state_h, state_c = model.get_layer(\"decoder_lstm\")(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = model.get_layer(\"decoder_output\")(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states, name=\"Decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:27:29.496537Z",
     "start_time": "2018-07-17T09:27:29.493922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build (index2char) dictionary for reverse lookup\n",
    "input_index2char = dict(\n",
    "    (i, char) for char, i in input_char2index.items())\n",
    "target_index2char = dict(\n",
    "    (i, char) for char, i in target_char2index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:27:29.583121Z",
     "start_time": "2018-07-17T09:27:29.497643Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    '''\n",
    "    Args:\n",
    "        input_seq: ndarray, encoder input\n",
    "    '''\n",
    "    # Encode the input as state vectors.\n",
    "    # Get (initial) state value from encoder give input_seq\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1. (1 sentence, 1 char which is a num_decoder_tokens vector)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character (<BOS> token).\n",
    "    target_seq[0, 0, target_char2index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        # Get prediction(along with hidden state h, and memory cell c) from decoder (character-wise)\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = target_index2char[sampled_token_index]    # lookup from index2char dict\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        #target_seq = output_tokens\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:27:30.243542Z",
     "start_time": "2018-07-17T09:27:29.584701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Allez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Ariliez !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Ariliez !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Aide-moi!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrtez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrtez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrtez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je l'ai ress.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Je plaise.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je vous ai !\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je vous ai !\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Qui chamme !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaquez !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaquez !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: tritez bles !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: tritez bles !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: tritez bles !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: tritez bles !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Va cherche.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Allez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Allez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Allez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris!\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Compris?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Compris?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Compris?\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Entre.\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Entre.\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Allez vous bles !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Allez vous bles !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis senti mal.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis senti mal.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je les ai courir.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je l'ai contrari.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je l'ai contrari.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: Je l'ai eu chauche.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: J'ai fait de moi.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis maline.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis maline.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: coute !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Prrt !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Prrt !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(50):\n",
    "    # Take one sequence (from training data)\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test (Single word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T09:31:54.527416Z",
     "start_time": "2018-07-17T09:31:54.512267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Hi\n",
      "Decoded sentence: Ent-el !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_seq = \"Hi\"\n",
    "# One-hot Encoding\n",
    "onehot_test_seq = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "for t, char in enumerate(test_seq):\n",
    "    onehot_test_seq[0, t, input_char2index[char]] = 1.\n",
    "\n",
    "decoded_sentence = decode_sequence(onehot_test_seq)\n",
    "print('Input sentence:', test_seq)\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "190px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 156,
   "position": {
    "height": "40px",
    "left": "1163px",
    "right": "61px",
    "top": "0px",
    "width": "696px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
